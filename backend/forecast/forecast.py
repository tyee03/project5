import warnings
import gc
import sys
import os
import pandas as pd
import numpy as np
from tqdm.auto import tqdm
from datetime import datetime, date
from dateutil.relativedelta import relativedelta
from supabase import create_client, Client
from prophet import Prophet
from prophet.diagnostics import cross_validation, performance_metrics
from sklearn.metrics import mean_absolute_percentage_error
import pmdarima as pm
from sklearn.linear_model import LogisticRegression
import multiprocessing

warnings.filterwarnings("ignore")

# --- Supabase ì ‘ì† ì •ë³´ ë° ì „ì—­ ë³€ìˆ˜ ì„¤ì • ---
SUPABASE_URL = os.environ.get("SUPABASE_URL", "https://rfgtrniqfimnpvheqkaw.supabase.co")
SUPABASE_KEY = os.environ.get("SUPABASE_KEY",
                              "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InJmZ3RybmlxZmltbnB2aGVxa2F3Iiwicm9sZSI6InNlcnZpY2Vfcm9sZSIsImlhdCI6MTc0OTAwMjE4OCwiZXhwIjoyMDY0NTc4MTg4fQ.XVZPaEqjIjE0OIryXhgbB6ZnOdmkuLl6W9USTsE36EI")

MIN_MONTHS = 12
BASE_FUTURE = 12
CV_PERIOD_D_PROPHET = 180  # 6ê°œì›”
CV_HORIZON_D_PROPHET = 90  # 3ê°œì›”
FUTURE_COUNT_STRATEGY = 'mean'
FUTURE_COUNT_WINDOW = 6
ARIMA_TEST_PERIODS = 3
FORECAST_TABLE_NAME = "customer_order_forecast"


# --- ë°ì´í„°ë² ì´ìŠ¤ í—¬í¼ í•¨ìˆ˜ ---
def create_supabase_client():
    try:
        client = create_client(SUPABASE_URL, SUPABASE_KEY)
        print("âœ… Supabase í´ë¼ì´ì–¸íŠ¸ê°€ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
        return client
    except Exception as e:
        print(f"ğŸ”¥ Supabase í´ë¼ì´ì–¸íŠ¸ ìƒì„± ì˜¤ë¥˜: {e}")
        return None


def load_data_from_supabase(client: Client):
    try:
        print("ğŸšš Supabaseì—ì„œ ë°ì´í„° ë¡œë”© ì¤‘...")
        orders_response = client.table('orders').select(
            'CONTACT_ID, ORDER_DATE, AMOUNT, contacts!inner(CUSTOMER_ID)'
        ).execute()
        activities_response = client.table('sales_activities').select(
            'CUSTOMER_ID, ACTIVITY_DATE, ACTIVITY_TYPE, OUTCOME'
        ).execute()
        orders_data = [
            {'CONTACT_ID': item['CONTACT_ID'], 'ORDER_DATE': item['ORDER_DATE'], 'AMOUNT': item['AMOUNT'],
             'CUSTOMER_ID': item['contacts']['CUSTOMER_ID'] if item.get('contacts') else None}
            for item in orders_response.data
        ]
        orders_df = pd.DataFrame(orders_data).dropna(subset=['CUSTOMER_ID'])
        activities_df = pd.DataFrame(activities_response.data)
        print(f"âœ… ë¡œë“œ ì™„ë£Œ: {len(orders_df)}ê°œì˜ ì£¼ë¬¸, {len(activities_df)}ê°œì˜ í™œë™.")
        return orders_df, activities_df
    except Exception as e:
        print(f"ğŸ”¥ Supabase ë°ì´í„° ë¡œë”© ì˜¤ë¥˜: {e}")
        return None, None


def preprocess_data(orders_df, activities_df):
    orders_df.rename(columns={"ORDER_DATE": "ORDERED_AT", "AMOUNT": "SALES_AMOUNT"}, inplace=True)
    orders_df["ORDERED_AT"] = pd.to_datetime(orders_df["ORDERED_AT"])
    orders_df["MONTH_TS"] = orders_df["ORDERED_AT"].dt.to_period("M").dt.to_timestamp()
    activities_df.rename(columns={"ACTIVITY_DATE": "CONTACTED_AT"}, inplace=True)
    activities_df["CONTACTED_AT"] = pd.to_datetime(activities_df["CONTACTED_AT"])
    activities_df["MONTH_TS"] = activities_df["CONTACTED_AT"].dt.to_period("M").dt.to_timestamp()
    return orders_df, activities_df


def update_or_insert_forecasts_db(client: Client, customer_id, forecast_df_to_save, table_name, current_run_datetime):
    """ì²« ë²ˆì§¸ ì½”ë“œì™€ ë™ì¼í•œ DB ì €ì¥ ë¡œì§ + PROBABILITY ì»¬ëŸ¼ ì¶”ê°€"""
    forecast_df_to_save['PREDICTED_DATE_ISO'] = pd.to_datetime(forecast_df_to_save['PREDICTED_DATE']).dt.strftime(
        '%Y-%m-%d')
    min_pred_date = forecast_df_to_save['PREDICTED_DATE_ISO'].min()
    max_pred_date = forecast_df_to_save['PREDICTED_DATE_ISO'].max()

    old_forecasts_df = pd.DataFrame(columns=['PREDICTED_DATE', 'MAPE'])

    try:
        print(f"Supabaseì—ì„œ ê³ ê° ID {customer_id}ì˜ ê¸°ì¡´ ì˜ˆì¸¡ ë°ì´í„° ì¡°íšŒ ì¤‘...")
        response = client.table(table_name).select('PREDICTED_DATE, MAPE').eq('CUSTOMER_ID', customer_id).gte(
            'PREDICTED_DATE', min_pred_date).lte('PREDICTED_DATE', max_pred_date).execute()

        if not response.data:
            print(f"Supabaseì—ì„œ ê³ ê° ID {customer_id}ì˜ ê¸°ì¡´ ì˜ˆì¸¡ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            old_forecasts_df = pd.DataFrame(response.data)
            if 'PREDICTED_DATE' in old_forecasts_df.columns:
                old_forecasts_df['PREDICTED_DATE'] = pd.to_datetime(old_forecasts_df['PREDICTED_DATE'])
            if 'MAPE' in old_forecasts_df.columns:
                old_forecasts_df['MAPE'] = pd.to_numeric(old_forecasts_df['MAPE'], errors='coerce')
            else:
                old_forecasts_df['MAPE'] = np.nan

    except Exception as e:
        print(f"!!! Supabase ê¸°ì¡´ ì˜ˆì¸¡ ë°ì´í„° ì¡°íšŒ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ (ê³ ê° ID: {customer_id}): {e}")
        old_forecasts_df = pd.DataFrame(columns=['PREDICTED_DATE', 'MAPE'])

    print(f"\n[DB ì‘ì—… ê²°ì •] ê³ ê° ID: {customer_id}...")
    for _, new_row in forecast_df_to_save.iterrows():
        new_pred_date_dt = new_row['PREDICTED_DATE']
        new_mape = new_row['MAPE'] if pd.notna(new_row['MAPE']) else None
        new_model_name = new_row['PREDICTION_MODEL']

        existing_record = old_forecasts_df[old_forecasts_df['PREDICTED_DATE'] == new_pred_date_dt]
        operation, reason = None, "ì¡°ê±´ ë¶ˆì¶©ì¡±"

        # ì‹¤íŒ¨ ì¼€ì´ìŠ¤ ì •ì˜ (Event-Driven ì¶”ê°€)
        is_failure_case = new_model_name in ["Data Insufficient", "Prediction Failed", "Event-Driven (Logistic)"]

        if existing_record.empty:
            operation, reason = 'INSERT', "ê¸°ì¡´ ì˜ˆì¸¡ ì—†ìŒ"
        elif is_failure_case:
            operation, reason = 'UPDATE', f"'{new_model_name}' ìƒíƒœì´ë¯€ë¡œ ê¸°ì¡´ ë°ì´í„°ë¥¼ ë®ì–´ì“°ê¸°"
        else:
            # ì„±ê³µì ì¸ ì˜ˆì¸¡ì˜ ê²½ìš°ì—ë§Œ MAPEë¥¼ ë¹„êµ
            old_mape = existing_record.iloc[0]['MAPE']
            if pd.isna(old_mape):
                operation, reason = 'UPDATE', "ê¸°ì¡´ MAPE ì—†ìŒ"
            elif new_mape is not None and old_mape is not None and new_mape < old_mape:
                operation, reason = 'UPDATE', f"ì„±ëŠ¥ í–¥ìƒ (ê¸°ì¡´ MAPE: {old_mape:.2f}% -> ìƒˆ MAPE: {new_mape:.2f}%)"
            else:
                reason = f"ì„±ëŠ¥ ì €í•˜/ë™ì¼ (ê¸°ì¡´ MAPE: {old_mape:.2f}% (ë˜ëŠ” None), ìƒˆ MAPE: {new_mape})->ì—…ë°ì´íŠ¸ ì•ˆí•¨"

        print(f"  - ë‚ ì§œ: {new_pred_date_dt.strftime('%Y-%m-%d')}, ê²°ì •: {operation or 'ì‘ì—… ì—†ìŒ'}, ì´ìœ : {reason}")

        # ì²« ë²ˆì§¸ ì½”ë“œì™€ ë™ì¼í•œ DB payload êµ¬ì¡° + PROBABILITY ì¶”ê°€
        db_payload = {
            'CUSTOMER_ID': int(customer_id),
            'PREDICTED_DATE': new_pred_date_dt.strftime('%Y-%m-%d'),
            'PREDICTED_QUANTITY': new_row['PREDICTED_QUANTITY'],
            'MAPE': new_mape,
            'PREDICTION_MODEL': new_model_name,
            'PROBABILITY': new_row.get('PROBABILITY'),  # í™•ë¥  ê°’ ì¶”ê°€
            'FORECAST_GENERATION_DATETIME': current_run_datetime.isoformat()
        }

        try:
            if operation == 'INSERT':
                client.table(table_name).insert(db_payload).execute()
            elif operation == 'UPDATE':
                client.table(table_name).update(db_payload).eq('CUSTOMER_ID', customer_id).eq('PREDICTED_DATE',
                                                                                              new_pred_date_dt.strftime(
                                                                                                  '%Y-%m-%d')).execute()
        except Exception as e:
            print(
                f"!!! Supabase {operation} ì‘ì—… ì‹¤íŒ¨ (ê³ ê° ID: {customer_id}, ë‚ ì§œ: {new_pred_date_dt.strftime('%Y-%m-%d')}): {e}")


def create_event_features(orders, activities):
    print("ğŸ“Š Bê·¸ë£¹ìš© ì´ë²¤íŠ¸ ì˜ˆì¸¡ ëª¨ë¸ì˜ í•™ìŠµ ë°ì´í„° ìƒì„± ì¤‘...")
    if orders.empty:
        print("âš ï¸ ì£¼ë¬¸ ë°ì´í„°ê°€ ì—†ì–´ í•™ìŠµ ë°ì´í„°ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None, None, None

    large_order_threshold = orders['SALES_AMOUNT'].quantile(0.75)
    orders['IS_LARGE_ORDER'] = orders['SALES_AMOUNT'] >= large_order_threshold

    keywords = ['ê²¬ì ', 'êµì²´', 'ëŒ€ê·œëª¨', 'ì‹ ê·œ', 'ì œì•ˆ']
    activities['IS_KEY_ACTIVITY'] = activities['ACTIVITY_TYPE'].str.contains('|'.join(keywords), na=False)

    all_months = pd.date_range(start=orders['MONTH_TS'].min(), end=pd.to_datetime(date.today()), freq='MS')
    all_customers = orders['CUSTOMER_ID'].unique()
    training_df = pd.MultiIndex.from_product([all_customers, all_months], names=['CUSTOMER_ID', 'MONTH_TS']).to_frame(
        index=False)

    key_activities_monthly = activities[activities['IS_KEY_ACTIVITY']].groupby(
        ['CUSTOMER_ID', 'MONTH_TS']).size().reset_index(name='KEY_ACTIVITY_COUNT')
    training_df = pd.merge(training_df, key_activities_monthly, on=['CUSTOMER_ID', 'MONTH_TS'], how='left').fillna(0)
    training_df['KEY_ACTIVITY_LAST_6M'] = training_df.groupby('CUSTOMER_ID')['KEY_ACTIVITY_COUNT'].transform(
        lambda x: x.rolling(6, min_periods=1).sum())

    large_orders = orders[orders['IS_LARGE_ORDER']]
    last_large_order_month = large_orders.groupby('CUSTOMER_ID')['MONTH_TS'].max().reset_index().rename(
        columns={'MONTH_TS': 'LAST_LARGE_ORDER_TS'})
    training_df = pd.merge(training_df, last_large_order_month, on='CUSTOMER_ID', how='left')

    training_df['MONTHS_SINCE_LAST_LARGE'] = (
                (training_df['MONTH_TS'].dt.year - training_df['LAST_LARGE_ORDER_TS'].dt.year) * 12 +
                (training_df['MONTH_TS'].dt.month - training_df['LAST_LARGE_ORDER_TS'].dt.month))
    training_df['MONTHS_SINCE_LAST_LARGE'] = training_df.groupby('CUSTOMER_ID')[
        'MONTHS_SINCE_LAST_LARGE'].ffill().fillna(120).clip(lower=0)

    large_order_monthly = large_orders.groupby(['CUSTOMER_ID', 'MONTH_TS']).size().reset_index(name='HAS_LARGE_ORDER')
    training_df = pd.merge(training_df, large_order_monthly[['CUSTOMER_ID', 'MONTH_TS', 'HAS_LARGE_ORDER']],
                           on=['CUSTOMER_ID', 'MONTH_TS'], how='left').fillna(0)
    training_df['TARGET'] = training_df.groupby('CUSTOMER_ID')['HAS_LARGE_ORDER'].transform(
        lambda x: x.rolling(6, min_periods=1).max().shift(-6)).fillna(0)

    features = ['KEY_ACTIVITY_LAST_6M', 'MONTHS_SINCE_LAST_LARGE']
    X = training_df[features]
    y = training_df['TARGET']

    print("âœ… í•™ìŠµ ë°ì´í„° ìƒì„± ì™„ë£Œ.")
    return X, y, training_df


def train_event_model(X, y):
    print("ğŸ§  Bê·¸ë£¹ìš© ì´ë²¤íŠ¸ ì˜ˆì¸¡ ëª¨ë¸ í•™ìŠµ ì¤‘...")
    model = LogisticRegression(class_weight='balanced', random_state=42)
    model.fit(X, y)
    print("âœ… ëª¨ë¸ í•™ìŠµ ì™„ë£Œ.")
    return model


# --- ë©”ì¸ íŒŒì´í”„ë¼ì¸ ---
def run_monthly_forecast_pipeline():
    supabase = create_supabase_client()
    if not supabase: return

    orders, activities_df = load_data_from_supabase(supabase)
    if orders is None or orders.empty:
        print("ì£¼ë¬¸ ë°ì´í„°ê°€ ì—†ì–´ íŒŒì´í”„ë¼ì¸ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return

    orders, activities_df = preprocess_data(orders, activities_df)
    forecast_generation_datetime = datetime.now()
    future_start_date = pd.to_datetime(date.today()).to_period("M").to_timestamp()
    future_dates_fixed = pd.date_range(start=future_start_date, periods=BASE_FUTURE, freq="MS")

    # --- 1. ì´ë²¤íŠ¸ ì˜ˆì¸¡ ëª¨ë¸ í•™ìŠµ ---
    X_train, y_train, training_df_full = create_event_features(orders, activities_df)
    event_model = train_event_model(X_train, y_train)

    # --- 2. Bê·¸ë£¹(íŠ¹ë³„ ê´€ë¦¬) ë¶„ë¥˜ ---
    print("\nğŸ“Š 'íŠ¹ë³„ ê´€ë¦¬ ê³ ê°(Bê·¸ë£¹)' ë¶„ë¥˜ ì¤‘...")
    customer_first_order = orders.groupby('CUSTOMER_ID')['MONTH_TS'].min()
    customer_active_months = orders.groupby('CUSTOMER_ID')['MONTH_TS'].nunique()
    current_month_period = pd.to_datetime(date.today()).to_period('M')
    total_lifespan_months = ((current_month_period.year - customer_first_order.dt.year) * 12 + (
                current_month_period.month - customer_first_order.dt.month) + 1).fillna(0)
    total_lifespan_months[total_lifespan_months <= 0] = 1
    active_ratio = (customer_active_months / total_lifespan_months).fillna(0)
    INACTIVITY_RATIO_THRESHOLD = 0.90
    group_b_customer_ids = set(active_ratio[active_ratio <= (1 - INACTIVITY_RATIO_THRESHOLD)].index)
    print(f"âœ… ë¶„ë¥˜ ì™„ë£Œ: ì´ {len(group_b_customer_ids)}ëª…ì˜ ê³ ê°ì´ íŠ¹ë³„ ê´€ë¦¬ ê·¸ë£¹(Bê·¸ë£¹)ìœ¼ë¡œ ë¶„ë¥˜ë˜ì—ˆìŠµë‹ˆë‹¤.")

    # Bê·¸ë£¹ ê³ ê°ì˜ ê³¼ê±° ëŒ€ëŸ‰ ì£¼ë¬¸ í‰ê· ì•¡ ê³„ì‚°
    large_order_threshold = orders['SALES_AMOUNT'].quantile(0.75)
    avg_large_order_amount = orders[orders['SALES_AMOUNT'] >= large_order_threshold].groupby('CUSTOMER_ID')[
        'SALES_AMOUNT'].mean()

    potential_regressors = ['total_activities_count']
    if 'ACTIVITY_TYPE' in activities_df.columns:
        potential_regressors.extend(
            [f'act_type_{str(act).replace(" ", "_")}' for act in activities_df['ACTIVITY_TYPE'].dropna().unique()])
    if 'OUTCOME' in activities_df.columns:
        potential_regressors.extend(
            [f'outcome_{str(out).replace(" ", "_")}' for out in activities_df['OUTCOME'].dropna().unique()])

    for cust_id, grp_orders in tqdm(orders.groupby("CUSTOMER_ID"), desc="ê³ ê°ë³„ ì˜ˆì¸¡"):
        print(f"\n--- ê³ ê° ID: {cust_id} ì˜ˆì¸¡ ì‹œì‘ ---")

        if cust_id in group_b_customer_ids:
            # --- ê·¸ë£¹ B: ì´ë²¤íŠ¸ ì˜ˆì¸¡ ---
            print(f"â¡ï¸  ê·¸ë£¹ B (ì´ë²¤íŠ¸ ì˜ˆì¸¡): íŠ¹ë³„ ê´€ë¦¬ ëŒ€ìƒìœ¼ë¡œ ë¶„ë¥˜ë˜ì—ˆìŠµë‹ˆë‹¤.")

            future_features_list = []
            base_months_since = \
            training_df_full[training_df_full['CUSTOMER_ID'] == cust_id]['MONTHS_SINCE_LAST_LARGE'].iloc[-1]
            base_activities = training_df_full[training_df_full['CUSTOMER_ID'] == cust_id]['KEY_ACTIVITY_LAST_6M'].iloc[
                -1]

            for i in range(BASE_FUTURE):
                future_features_list.append(
                    {'KEY_ACTIVITY_LAST_6M': base_activities, 'MONTHS_SINCE_LAST_LARGE': base_months_since + i + 1})

            future_features_df = pd.DataFrame(future_features_list)
            purchase_probabilities = event_model.predict_proba(future_features_df)[:, 1]

            purchase_threshold = 0.5
            avg_order_val = avg_large_order_amount.get(cust_id, 0)
            predicted_quantities = [avg_order_val if prob >= purchase_threshold else 0 for prob in
                                    purchase_probabilities]

            chosen_model_name = "Event-Driven (Logistic)"
            chosen_forecast = pd.DataFrame(
                {'ds': future_dates_fixed, 'yhat': predicted_quantities, 'PROBABILITY': purchase_probabilities})
            chosen_mape = None

        else:
            # --- ê·¸ë£¹ A: ì‹œê³„ì—´ ì˜ˆì¸¡ (Prophet + ARIMA) ---
            print(f"â¡ï¸  ê·¸ë£¹ A (ì‹œê³„ì—´ ì˜ˆì¸¡): ì¼ë°˜ ì˜ˆì¸¡ ëŒ€ìƒìœ¼ë¡œ ë¶„ë¥˜ë˜ì—ˆìŠµë‹ˆë‹¤.")
            df_sales = grp_orders.groupby("MONTH_TS")["SALES_AMOUNT"].sum().reset_index().rename(
                columns={"MONTH_TS": "ds", "SALES_AMOUNT": "y"})
            df_sales["ds"] = pd.to_datetime(df_sales["ds"])
            customer_activities = activities_df[activities_df["CUSTOMER_ID"] == cust_id].copy()
            df_model_input = df_sales.copy()

            if not customer_activities.empty:
                df_model_input = pd.merge(df_model_input, customer_activities.groupby("MONTH_TS").size().reset_index(
                    name="total_activities_count").rename(columns={"MONTH_TS": "ds"}), on="ds", how="left")
                if 'ACTIVITY_TYPE' in customer_activities.columns:
                    dummies_activities_type = pd.get_dummies(customer_activities, columns=['ACTIVITY_TYPE'],
                                                             prefix='act_type', dtype=int)
                    df_model_input = pd.merge(df_model_input, dummies_activities_type.groupby("MONTH_TS").sum(
                        numeric_only=True).reset_index().rename(columns={"MONTH_TS": "ds"}), on="ds", how="left")
                if 'OUTCOME' in customer_activities.columns:
                    dummies_outcomes = pd.get_dummies(customer_activities, columns=['OUTCOME'], prefix='outcome',
                                                      dtype=int)
                    df_model_input = pd.merge(df_model_input, dummies_outcomes.groupby("MONTH_TS").sum(
                        numeric_only=True).reset_index().rename(columns={"MONTH_TS": "ds"}), on="ds", how="left")

            for col in potential_regressors:
                if col not in df_model_input.columns:
                    df_model_input[col] = 0
            df_model_input.fillna(0, inplace=True)

            active_regressors = [col for col in potential_regressors if
                                 df_model_input[col].sum() > 0 and col in df_model_input.columns]

            print(f"ëª¨ë¸ ì…ë ¥ ë°ì´í„° í¬ê¸°: {len(df_model_input)}, í™œì„± íšŒê·€ ë³€ìˆ˜: {active_regressors}")

            chosen_model_name, chosen_forecast, chosen_mape = "Data Insufficient", None, None

            if len(df_model_input) >= MIN_MONTHS:
                future_regressor_values = {col: round(df_model_input[col].tail(FUTURE_COUNT_WINDOW).mean()) for col in
                                           active_regressors}
                print(f"ë¯¸ë˜ íšŒê·€ ë³€ìˆ˜ ê°’ (í‰ê· ): {future_regressor_values}")

                # Prophet ëª¨ë¸ ì‹œë„
                prophet_forecast, prophet_mape = None, None
                print("Prophet ëª¨ë¸ ì‹œë„ ì¤‘...")
                try:
                    model_prophet = Prophet(yearly_seasonality=True, seasonality_mode="additive",
                                            stan_backend="CMDSTANPY")
                    for reg in active_regressors:
                        model_prophet.add_regressor(reg)
                    model_prophet.fit(df_model_input[['ds', 'y'] + active_regressors])

                    future_df_prophet = pd.DataFrame({'ds': future_dates_fixed})
                    for reg, val in future_regressor_values.items():
                        future_df_prophet[reg] = val

                    forecast_p = model_prophet.predict(future_df_prophet)
                    prophet_forecast = forecast_p[['ds', 'yhat']]

                    # Prophet êµì°¨ ê²€ì¦ (ì²« ë²ˆì§¸ ì½”ë“œì™€ ë™ì¼)
                    print("Prophet êµì°¨ ê²€ì¦ ì‹œì‘ (parallel=None)...")
                    cv_results = cross_validation(model_prophet, initial=f'{CV_PERIOD_D_PROPHET * 3} days',
                                                  period=f'{CV_PERIOD_D_PROPHET} days',
                                                  horizon=f'{CV_HORIZON_D_PROPHET} days', parallel=None,
                                                  disable_tqdm=True)

                    if not cv_results.empty:
                        metrics = performance_metrics(cv_results)
                        prophet_mape = metrics['mape'].mean() * 100
                        print(f"Prophet MAPE (ê³ ê° ID: {cust_id}): {prophet_mape:.2f}%")
                    else:
                        print(f"Prophet êµì°¨ ê²€ì¦ ê²°ê³¼ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. (ê³ ê° ID: {cust_id})")
                        prophet_mape = None
                except Exception as e:
                    print(f"!!! Prophet ëª¨ë¸ë§ ì‹¤íŒ¨ (ê³ ê° ID: {cust_id}): {e}")
                    prophet_forecast, prophet_mape = None, None

                # ARIMA ëª¨ë¸ ì‹œë„ (ì²« ë²ˆì§¸ ì½”ë“œì™€ ë™ì¼ ë¡œì§)
                arima_forecast, arima_mape = None, None
                print("ARIMA ëª¨ë¸ ì‹œë„ ì¤‘...")
                if len(df_model_input) >= 12 + ARIMA_TEST_PERIODS:
                    try:
                        y_series = df_model_input.set_index("ds")["y"].asfreq("MS").interpolate()
                        exog_series = df_model_input.set_index("ds")[active_regressors].asfreq(
                            "MS").interpolate() if active_regressors else None

                        train_y, test_y = y_series[:-ARIMA_TEST_PERIODS], y_series[-ARIMA_TEST_PERIODS:]
                        train_exog, test_exog = (exog_series[:-ARIMA_TEST_PERIODS],
                                                 exog_series[-ARIMA_TEST_PERIODS:]) if exog_series is not None else (
                        None, None)

                        eval_model = pm.auto_arima(train_y, exogenous=train_exog, m=12, seasonal=True,
                                                   suppress_warnings=True, stepwise=True, error_action='ignore')
                        test_pred = eval_model.predict(n_periods=len(test_y), exogenous=test_exog)

                        if np.all(test_y > 0):
                            arima_mape = mean_absolute_percentage_error(test_y, test_pred) * 100
                            print(f"ARIMA MAPE (ê³ ê° ID: {cust_id}): {arima_mape:.2f}%")
                        else:
                            arima_mape = None

                        final_model = pm.auto_arima(y_series, exogenous=exog_series, m=12, seasonal=True,
                                                    suppress_warnings=True, stepwise=True, error_action='ignore')

                        last_data_date = y_series.index[-1]
                        gap_months = (future_start_date.year - last_data_date.year) * 12 + (
                                    future_start_date.month - last_data_date.month)
                        gap_months = max(0, gap_months)
                        total_periods_to_predict = gap_months + BASE_FUTURE

                        future_exog = None
                        if active_regressors:
                            future_exog_dates = pd.date_range(start=last_data_date + relativedelta(months=1),
                                                              periods=total_periods_to_predict, freq="MS")
                            future_exog = pd.DataFrame(future_regressor_values, index=future_exog_dates)
                            if exog_series is not None:
                                future_exog = future_exog[exog_series.columns]

                        full_future_pred = final_model.predict(n_periods=total_periods_to_predict,
                                                               exogenous=future_exog)
                        future_pred = full_future_pred.iloc[-BASE_FUTURE:]

                        arima_forecast = pd.DataFrame({"ds": future_pred.index, "yhat": future_pred.values})

                    except Exception as e:
                        print(f"!!! ARIMA ëª¨ë¸ë§ ì‹¤íŒ¨ (ê³ ê° ID: {cust_id}): {e}")
                        arima_forecast, arima_mape = None, None
                else:
                    print(f"ARIMA ëª¨ë¸ë§ì„ ìœ„í•œ ë°ì´í„° ë¶€ì¡± (ê³ ê° ID: {cust_id}).")

                # ëª¨ë¸ ì„ íƒ ë¡œì§ (ì²« ë²ˆì§¸ ì½”ë“œì™€ ë™ì¼)
                if prophet_mape is not None and (arima_mape is None or prophet_mape < arima_mape):
                    chosen_forecast, chosen_mape, chosen_model_name = prophet_forecast, prophet_mape, "Prophet"
                    print(f"ìµœì¢… ì„ íƒ ëª¨ë¸: Prophet (MAPE: {prophet_mape:.2f}%)")
                elif arima_mape is not None:
                    chosen_forecast, chosen_mape, chosen_model_name = arima_forecast, arima_mape, "ARIMA"
                    print(f"ìµœì¢… ì„ íƒ ëª¨ë¸: ARIMA (MAPE: {arima_mape:.2f}%)")
                elif prophet_forecast is not None:
                    chosen_forecast, chosen_mape, chosen_model_name = prophet_forecast, prophet_mape, "Prophet (No MAPE)"
                    print(f"ìµœì¢… ì„ íƒ ëª¨ë¸: Prophet (MAPE ì—†ìŒ)")
                else:
                    chosen_model_name = "Prediction Failed"
                    chosen_forecast = pd.DataFrame({'ds': future_dates_fixed, 'yhat': 0})
                    print(f"!!! ì˜ˆì¸¡ ì‹¤íŒ¨. (ê³ ê° ID: {cust_id})")
            else:
                chosen_model_name = "Data Insufficient"
                chosen_forecast = pd.DataFrame({'ds': future_dates_fixed, 'yhat': 0})
                print(f"ë°ì´í„° ë¶€ì¡± (ê³ ê° ID: {cust_id}).")

        # --- ê³µí†µ í›„ì²˜ë¦¬ ë° ì €ì¥ ë¡œì§ ---
        chosen_forecast["yhat"] = np.maximum(0, chosen_forecast["yhat"])
        final_df_for_db = chosen_forecast.rename(columns={"ds": "PREDICTED_DATE", "yhat": "PREDICTED_QUANTITY"})
        final_df_for_db["MAPE"] = chosen_mape
        final_df_for_db["PREDICTION_MODEL"] = chosen_model_name

        # PROBABILITY ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ Noneìœ¼ë¡œ ì„¤ì •
        if 'PROBABILITY' not in final_df_for_db.columns:
            final_df_for_db['PROBABILITY'] = None

        print(f"ğŸ’¾ ìµœì¢… ì˜ˆì¸¡ ë°ì´í„° (ëª¨ë¸: {chosen_model_name}):")
        print(final_df_for_db.head())
        print(f"DB ì €ì¥ë  ë°ì´í„° ìˆ˜: {len(final_df_for_db)}")

        update_or_insert_forecasts_db(supabase, cust_id, final_df_for_db, FORECAST_TABLE_NAME,
                                      forecast_generation_datetime)

        gc.collect()


if __name__ == '__main__':
    if sys.platform.startswith('win'):
        multiprocessing.freeze_support()

    print("ğŸš€ ì›”ë³„ ì£¼ë¬¸ ì˜ˆì¸¡ íŒŒì´í”„ë¼ì¸ ì‹œì‘...")
    try:
        run_monthly_forecast_pipeline()
    except Exception as e:
        print(f"!!! ì›”ë³„ ì£¼ë¬¸ ì˜ˆì¸¡ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì¤‘ ì¹˜ëª…ì ì¸ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback

        traceback.print_exc()

    print("ğŸ ì›”ë³„ ì£¼ë¬¸ ì˜ˆì¸¡ íŒŒì´í”„ë¼ì¸ ì¢…ë£Œ.")
